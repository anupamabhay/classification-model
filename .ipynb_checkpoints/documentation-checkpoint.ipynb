{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model Documentation\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook provides an interactive walkthrough of our baseline classification model results. The model was built using a production-ready pipeline with XGBoost as the core classifier.\n",
    "\n",
    "### Business Problem\n",
    "This project implements a binary classification solution using automated preprocessing and XGBoost modeling. The goal is to create a robust, reproducible baseline that can serve as a foundation for more advanced modeling efforts.\n",
    "\n",
    "### Dataset\n",
    "- Source: `data/source_data.csv`\n",
    "- Target variable: 'target' column\n",
    "- Preprocessing: Automatic detection of numerical/categorical features with appropriate scaling and encoding\n",
    "\n",
    "### Model Pipeline\n",
    "1. **Preprocessing**: StandardScaler for numerical features, OneHotEncoder for categorical features\n",
    "2. **Model**: XGBoost Classifier with default parameters\n",
    "3. **Evaluation**: Comprehensive metrics including accuracy, precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model Artifacts\n",
    "\n",
    "Let's load the trained model and performance metrics generated by `train_model.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model\n",
    "model_path = Path('./output/model.joblib')\n",
    "if model_path.exists():\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"[SUCCESS] Model loaded successfully\")\n",
    "    print(f\"Model type: {type(model)}\")\n",
    "else:\n",
    "    print(\"[ERROR] Model file not found. Please run train_model.py first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load performance metrics\n",
    "metrics_path = Path('./output/performance_metrics.json')\n",
    "if metrics_path.exists():\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    print(\"[SUCCESS] Performance metrics loaded successfully\")\n",
    "else:\n",
    "    print(\"[ERROR] Metrics file not found. Please run train_model.py first.\")\n",
    "    metrics = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metrics:\n",
    "    print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 40)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric.upper():.<20} {value:.4f}\")\n",
    "    \n",
    "    # Create a performance summary DataFrame for better visualization\n",
    "    performance_df = pd.DataFrame([\n",
    "        {'Metric': metric.replace('_', ' ').title(), 'Score': f\"{value:.4f}\"}\n",
    "        for metric, value in metrics.items()\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nPerformance Table:\")\n",
    "    display(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "cm_path = Path('./output/plots/confusion_matrix.png')\n",
    "if cm_path.exists():\n",
    "    print(\"Confusion Matrix:\")\n",
    "    display(Image(str(cm_path)))\n",
    "else:\n",
    "    print(\"[ERROR] Confusion matrix plot not found. Please run train_model.py first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals():\n",
    "    print(\"PIPELINE STRUCTURE\")\n",
    "    print(\"=\" * 30)\n",
    "    print(model)\n",
    "    \n",
    "    # Display preprocessing steps\n",
    "    preprocessor = model.named_steps['preprocessor']\n",
    "    print(\"\\nPreprocessing Steps:\")\n",
    "    for name, transformer, features in preprocessor.transformers_:\n",
    "        print(f\"  - {name}: {transformer.__class__.__name__}\")\n",
    "        if hasattr(features, '__len__') and len(features) > 0:\n",
    "            print(f\"    Features ({len(features)}): {features[:3]}{'...' if len(features) > 3 else ''}\")\n",
    "    \n",
    "    # Display classifier info\n",
    "    classifier = model.named_steps['classifier']\n",
    "    print(f\"\\nClassifier: {classifier.__class__.__name__}\")\n",
    "    print(f\"   Random State: {classifier.random_state}\")\n",
    "    print(f\"   Eval Metric: {classifier.eval_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "### Performance Metrics Explained:\n",
    "\n",
    "- **Accuracy**: Overall percentage of correct predictions\n",
    "- **Precision**: Of all positive predictions, how many were actually positive? (Reduces false positives)\n",
    "- **Recall**: Of all actual positives, how many were correctly identified? (Reduces false negatives)\n",
    "- **F1-Score**: Harmonic mean of precision and recall (balanced measure)\n",
    "\n",
    "### Model Characteristics:\n",
    "\n",
    "- **XGBoost Classifier**: Gradient boosting algorithm known for excellent performance on tabular data\n",
    "- **Automated Preprocessing**: Handles both numerical and categorical features appropriately\n",
    "- **Stratified Splitting**: Ensures balanced representation in train/test sets\n",
    "- **Reproducible Results**: Fixed random seeds ensure consistent results across runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps & Recommendations\n",
    "\n",
    "### Immediate Improvements:\n",
    "1. **Hyperparameter Tuning**: Use GridSearchCV or RandomizedSearchCV to optimize XGBoost parameters\n",
    "2. **Feature Engineering**: Create domain-specific features or polynomial combinations\n",
    "3. **Cross-Validation**: Implement k-fold CV for more robust performance estimation\n",
    "\n",
    "### Advanced Enhancements:\n",
    "1. **Ensemble Methods**: Combine multiple models (Random Forest, LightGBM, etc.)\n",
    "2. **Feature Selection**: Use SelectKBest or recursive feature elimination\n",
    "3. **Imbalanced Data Handling**: Apply SMOTE or class weighting if needed\n",
    "4. **Model Interpretation**: Add SHAP values for feature importance analysis\n",
    "\n",
    "### Production Considerations:\n",
    "1. **Model Monitoring**: Track performance degradation over time\n",
    "2. **A/B Testing**: Compare against current production model\n",
    "3. **Automated Retraining**: Set up pipelines for regular model updates\n",
    "4. **API Deployment**: Wrap model in FastAPI or similar framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This baseline classification model provides a solid foundation for binary classification tasks. The automated preprocessing pipeline ensures robust handling of mixed data types, while XGBoost delivers strong predictive performance out of the box.\n",
    "\n",
    "The modular, script-first approach ensures that the core logic is production-ready and can be easily deployed, monitored, and improved upon in future iterations.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Automated, reproducible pipeline\n",
    "- Comprehensive evaluation metrics\n",
    "- Production-ready code structure\n",
    "- Clear documentation and visualization\n",
    "\n",
    "*Ready for the next phase of development!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification Model",
   "language": "python",
   "name": "classification-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}